{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 628,
     "status": "ok",
     "timestamp": 1683237783209,
     "user": {
      "displayName": "Sushant Karki",
      "userId": "10159480926888285206"
     },
     "user_tz": 240
    },
    "id": "el5KWW5siA2f",
    "outputId": "a55ce0cb-c47e-4313-a384-8b7d452408b0"
   },
   "outputs": [],
   "source": [
    "# !wget \"https://raw.githubusercontent.com/00ber/ml-projects/main/data/weight_diff.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1683237784184,
     "user": {
      "displayName": "Sushant Karki",
      "userId": "10159480926888285206"
     },
     "user_tz": 240
    },
    "id": "liIcifRfiIhb"
   },
   "outputs": [],
   "source": [
    "## Neural Network model + Training code \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "class PUFWeightsPredictor(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dims=64, output_dims=1, weights_init=None):\n",
    "        super(PUFWeightsPredictor, self).__init__()\n",
    "        self.input_dims = input_dims\n",
    "        self.output_dims = output_dims\n",
    "\n",
    "        self.fc = nn.Linear(input_dims + 1, 1, bias=False)\n",
    "        self.training = True\n",
    "        if isinstance(weights_init, tuple):\n",
    "          nn.init.uniform_(self.fc.weight, a=weights_init[0], b=weights_init[1])\n",
    "        elif weights_init is not None:\n",
    "          nn.init.normal_(self.fc.weight, mean=0.0, std=weights_init)\n",
    "\n",
    "    def forward(self, phi):\n",
    "      return self.fc(phi)\n",
    "\n",
    "    def get_weights(self):\n",
    "      state = self.state_dict().copy()\n",
    "      wt = state[\"fc.weight\"]\n",
    "      wt = wt.reshape(self.input_dims + 1, 1).cpu().numpy()\n",
    "      return wt\n",
    "\n",
    "class Trainer:\n",
    "  def __init__(self, model, num_epochs, lr, batch_size, train_ds, val_ds):\n",
    "    self.model = model\n",
    "    self.num_epochs = num_epochs\n",
    "    self.lr = lr \n",
    "    self.batch_size = batch_size\n",
    "    self.train_ds = train_ds\n",
    "    self.val_ds = val_ds\n",
    "    self.train_dl = DataLoader(\n",
    "        self.train_ds, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True\n",
    "    )\n",
    "    self.val_dl = DataLoader(\n",
    "        self.val_ds, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True\n",
    "    )\n",
    "   \n",
    "\n",
    "  def train(self):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    # optimizer = Adam(self.model.parameters(), lr=self.lr)\n",
    "    optimizer = SGD(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    self.model = self.model.to(device)\n",
    "    print(\"Begin training...\") \n",
    "\n",
    "    for epoch in range(1, self.num_epochs + 1): \n",
    "        running_train_loss = 0.0 \n",
    "        running_val_loss = 0.0 \n",
    "\n",
    "        # Training Loop \n",
    "        self.model.train()\n",
    "        for train_batch in self.train_dl:\n",
    "            inputs, outputs = train_batch  \n",
    "            inputs = inputs.to(device)\n",
    "            outputs = outputs.to(device)\n",
    "            optimizer.zero_grad()   \n",
    "            predicted_outputs = self.model(inputs)  \n",
    "            predicted_outputs = predicted_outputs.to(device)\n",
    "            train_loss = criterion(predicted_outputs, outputs) \n",
    "            train_loss.backward()   \n",
    "            optimizer.step()   \n",
    "\n",
    "            running_train_loss += train_loss.item() \n",
    "            \n",
    "        # Calculate training loss value \n",
    "        train_loss_value = running_train_loss/len(self.train_dl) \n",
    "\n",
    "        # Validation Loop \n",
    "        with torch.no_grad(): \n",
    "            self.model.eval() \n",
    "           \n",
    "            for val_batch in self.val_dl:\n",
    "               inputs, outputs = val_batch \n",
    "               inputs = inputs.to(device)\n",
    "               outputs = outputs.to(device)\n",
    "               predicted_outputs = self.model(inputs) \n",
    "               predicted_outputs = predicted_outputs.to(device)\n",
    "               val_loss = criterion(predicted_outputs, outputs) \n",
    "               running_val_loss += val_loss.item()   \n",
    "               \n",
    "        # Calculate validation loss value \n",
    "        val_loss_value = running_val_loss/len(self.val_dl) \n",
    " \n",
    "        # Print the statistics of the epoch \n",
    "        print(f\"Epoch {epoch}/{self.num_epochs} Avg. training loss: {train_loss_value:.4f} Avg. val loss: {val_loss_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 9003,
     "status": "ok",
     "timestamp": 1683237793183,
     "user": {
      "displayName": "Sushant Karki",
      "userId": "10159480926888285206"
     },
     "user_tz": 240
    },
    "id": "e3tQZgwhiJJU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def puf_query(c, w):\n",
    "    n = c.shape[1]\n",
    "    phi = np.ones(n+1)\n",
    "    phi[n] = 1\n",
    "    for i in range(n-1, -1, -1):\n",
    "        phi[i] = (2*c[0,i]-1)*phi[i+1]\n",
    "\n",
    "    r = (np.dot(phi, w) > 0)\n",
    "    return r\n",
    "    \n",
    "# Problem Setup\n",
    "target = 0.99  # The desired prediction rate\n",
    "n = 64  # number of stages in the PUF\n",
    "\n",
    "# Initialize the PUF\n",
    "np.random.seed(int(time.time()))\n",
    "data = np.loadtxt('weight_diff.txt')\n",
    "w = np.zeros((n+1, 1))\n",
    "for i in range(1, n+2):\n",
    "    randi_offset = np.random.randint(1, 45481)\n",
    "    w[i-1] = data[randi_offset-1]\n",
    "\n",
    "# Syntax to query the PUF:\n",
    "c = np.random.randint(0, 2, size=(1, n))  # a random challenge vector\n",
    "r = puf_query(c, w)\n",
    "# you may remove these two lines\n",
    "\n",
    "# You can use the puf_query function to generate your training dataset\n",
    "# ADD YOUR DATASET GENERATION CODE HERE\n",
    "training_size = 10000\n",
    "X = np.random.randint(0, 2, size=(training_size, n))\n",
    "y = np.zeros((training_size, 1))\n",
    "\n",
    "for i in range(training_size):\n",
    "  y[i] = puf_query(X[i].reshape(1, -1), w)\n",
    "\n",
    "def calc_phi(select_bits):\n",
    "    phi_vals = []\n",
    "    for i in range(len(select_bits)):\n",
    "      target_slice = select_bits[i:]\n",
    "      zeros = [z for z in target_slice if z == 0]\n",
    "      phi = 1 if len(zeros) % 2 == 0 else -1\n",
    "      phi_vals.append(phi)\n",
    "    return np.array(phi_vals + [1])\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train_phi = np.apply_along_axis(calc_phi, 1, X_train)\n",
    "X_test_phi = np.apply_along_axis(calc_phi, 1, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1683237793183,
     "user": {
      "displayName": "Sushant Karki",
      "userId": "10159480926888285206"
     },
     "user_tz": 240
    },
    "id": "GMvGc5USEGKr"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1683237793184,
     "user": {
      "displayName": "Sushant Karki",
      "userId": "10159480926888285206"
     },
     "user_tz": 240
    },
    "id": "koFjF0jMiJMj"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_and_eval(params):\n",
    "  w0 = np.zeros((n+1, 1))  # The estimated value of w.\n",
    "  # Try to estimate the value of w here. This section will be timed. You are\n",
    "  # allowed to use the puf_query function here too, but it will count towards\n",
    "  # the training time.\n",
    "  results = []\n",
    "  lr = params[\"lr\"]\n",
    "  num_epochs = params[\"num_epochs\"] \n",
    "  weight_init = params[\"weight_init\"]\n",
    "  training_size = params[\"training_size\"] \n",
    "\n",
    "  train_dataset = TensorDataset(torch.from_numpy(X_train_phi[:training_size]).float(), torch.from_numpy(y_train[:training_size]).float())\n",
    "  val_dataset = TensorDataset(torch.from_numpy(X_test_phi).float(), torch.from_numpy(y_test).float())\n",
    "\n",
    "  t0 = time.process_time()\n",
    "\n",
    "  # ADD YOUR TRAINING CODE HERE\n",
    "  \n",
    "\n",
    "  model = PUFWeightsPredictor(n, 1, weight_init)\n",
    "  trainer = Trainer(\n",
    "      model=model, \n",
    "      num_epochs=num_epochs, \n",
    "      lr=lr,\n",
    "      batch_size=training_size, \n",
    "      train_ds=train_dataset, \n",
    "      val_ds=val_dataset\n",
    "  )\n",
    "  trainer.train()\n",
    "\n",
    "  t1 = time.process_time()\n",
    "  training_time = t1 - t0  # time taken to get w0\n",
    "  print(\"Training time:\", training_time)\n",
    "  print(\"Training size:\", training_size)\n",
    "\n",
    "\n",
    "  w0 = model.get_weights()\n",
    "\n",
    "  # Evaluate your result\n",
    "  n_test = 10000\n",
    "  correct = 0\n",
    "  for i in range(1, n_test+1):\n",
    "      c_test = np.random.randint(0, 2, size=(1, n))  # a random challenge vector\n",
    "      r = puf_query(c_test, w)\n",
    "      r0 = puf_query(c_test, w0)\n",
    "      correct += (r==r0)\n",
    "\n",
    "  success_rate = correct/n_test\n",
    "  print(\"Success rate:\", success_rate)\n",
    "\n",
    "\n",
    "  # If the success rate is less than 99%, a penalty time will be added\n",
    "  # One second is add for each 0.01% below 99%.\n",
    "  effective_training_time = training_time\n",
    "  if success_rate < 0.99:\n",
    "      effective_training_time = training_time + 10000*(0.99-success_rate)\n",
    "  print(\"Effective training time:\", effective_training_time)\n",
    "  results.append({\n",
    "        \"lr\": lr,\n",
    "        \"num_epochs\": num_epochs,\n",
    "        \"weight_init\": weight_init,\n",
    "        \"training_size\": training_size,\n",
    "        \"training_time\": training_time,\n",
    "        \"effective_training_time\": effective_training_time[0] if isinstance(effective_training_time, np.ndarray) else effective_training_time,\n",
    "        \"success_rate\": success_rate[0]\n",
    "  })\n",
    "  return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1683237793184,
     "user": {
      "displayName": "Sushant Karki",
      "userId": "10159480926888285206"
     },
     "user_tz": 240
    },
    "id": "wwzurOf1iYyP"
   },
   "outputs": [],
   "source": [
    "# params_grid = [\n",
    "#     {\n",
    "#       \"lr\": 300,\n",
    "#       \"num_epochs\": 10,\n",
    "#       \"weight_init\": (-30, 30),\n",
    "#       \"training_size\": 10000,\n",
    "#     },\n",
    "#     {\n",
    "#       \"lr\": 200,\n",
    "#       \"num_epochs\": 10,\n",
    "#       \"weight_init\": (-20, 20),\n",
    "#       \"training_size\": 10000,\n",
    "#     },\n",
    "#     {\n",
    "#       \"lr\": 200,\n",
    "#       \"num_epochs\": 10,\n",
    "#       \"weight_init\": (-10, 10),\n",
    "#       \"training_size\": 10000,\n",
    "#     },\n",
    "#     {\n",
    "#       \"lr\": 250,\n",
    "#       \"num_epochs\": 10,\n",
    "#       \"weight_init\": 1,\n",
    "#       \"training_size\": 10000,\n",
    "#     },\n",
    "    \n",
    "#     {\n",
    "#       \"lr\": 300,\n",
    "#       \"num_epochs\": 10,\n",
    "#       \"weight_init\": (-30, 30),\n",
    "#       \"training_size\": 5000,\n",
    "#     },\n",
    "#     {\n",
    "#       \"lr\": 200,\n",
    "#       \"num_epochs\": 10,\n",
    "#       \"weight_init\": (-20, 20),\n",
    "#       \"training_size\": 5000,\n",
    "#     },\n",
    "#     {\n",
    "#       \"lr\": 200,\n",
    "#       \"num_epochs\": 10,\n",
    "#       \"weight_init\": (-10, 10),\n",
    "#       \"training_size\": 5000,\n",
    "#     },\n",
    "#     {\n",
    "#       \"lr\": 250,\n",
    "#       \"num_epochs\": 10,\n",
    "#       \"weight_init\": 1,\n",
    "#       \"training_size\": 5000,\n",
    "#     },\n",
    "\n",
    "#     {\n",
    "#       \"lr\": 300,\n",
    "#       \"num_epochs\": 10,\n",
    "#       \"weight_init\": (-30, 30),\n",
    "#       \"training_size\": 15000,\n",
    "#     },\n",
    "#     {\n",
    "#       \"lr\": 200,\n",
    "#       \"num_epochs\": 10,\n",
    "#       \"weight_init\": (-20, 20),\n",
    "#       \"training_size\": 15000,\n",
    "#     },\n",
    "#     {\n",
    "#       \"lr\": 200,\n",
    "#       \"num_epochs\": 10,\n",
    "#       \"weight_init\": (-10, 10),\n",
    "#       \"training_size\": 15000,\n",
    "#     },\n",
    "#     {\n",
    "#       \"lr\": 250,\n",
    "#       \"num_epochs\": 10,\n",
    "#       \"weight_init\": 1,\n",
    "#       \"training_size\": 15000,\n",
    "#     },\n",
    "# ]\n",
    "# results = []\n",
    "# for params in params_grid:\n",
    "#   res = train_and_eval(params)\n",
    "#   for r in res:\n",
    "#     results.append(r)\n",
    "\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1683237793184,
     "user": {
      "displayName": "Sushant Karki",
      "userId": "10159480926888285206"
     },
     "user_tz": 240
    },
    "id": "ah7zv71eF1ip"
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# results_df = pd.DataFrame.from_dict(results)\n",
    "# pd.options.display.max_rows = 4000\n",
    "# results_df.sort_values(by=[\"success_rate\"], ascending=False).head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6808,
     "status": "ok",
     "timestamp": 1683237799983,
     "user": {
      "displayName": "Sushant Karki",
      "userId": "10159480926888285206"
     },
     "user_tz": 240
    },
    "id": "wWzxupOwGyHs",
    "outputId": "fd37e3fe-993d-4954-9261-a9af0215673d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin training...\n",
      "Epoch 1/10 Avg. training loss: 18.8087 Avg. val loss: 2.8482\n",
      "Epoch 2/10 Avg. training loss: 2.8229 Avg. val loss: 0.1360\n",
      "Epoch 3/10 Avg. training loss: 0.0908 Avg. val loss: 0.0461\n",
      "Epoch 4/10 Avg. training loss: 0.0176 Avg. val loss: 0.0223\n",
      "Epoch 5/10 Avg. training loss: 0.0090 Avg. val loss: 0.0187\n",
      "Epoch 6/10 Avg. training loss: 0.0069 Avg. val loss: 0.0155\n",
      "Epoch 7/10 Avg. training loss: 0.0063 Avg. val loss: 0.0148\n",
      "Epoch 8/10 Avg. training loss: 0.0060 Avg. val loss: 0.0139\n",
      "Epoch 9/10 Avg. training loss: 0.0059 Avg. val loss: 0.0136\n",
      "Epoch 10/10 Avg. training loss: 0.0058 Avg. val loss: 0.0134\n",
      "Training time: 0.234375\n",
      "Training size: 10000\n",
      "Success rate: [0.9961]\n",
      "Effective training time: 0.234375\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"lr\": 200,\n",
    "    \"num_epochs\": 10,\n",
    "    \"weight_init\": (-10, 10),\n",
    "    \"training_size\": 10000,\n",
    "}\n",
    "results = train_and_eval(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1683237799984,
     "user": {
      "displayName": "Sushant Karki",
      "userId": "10159480926888285206"
     },
     "user_tz": 240
    },
    "id": "y1YuqTONxrl2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOUabQT6z4SfCZUkDwQwUWA",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_cpu]",
   "language": "python",
   "name": "conda-env-pytorch_cpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
